from typing import Dict, Any, List, Generator
import json
import re
import traceback
from concurrent.futures import ThreadPoolExecutor, TimeoutError

from app.llm.client import llm
from app.agents.test_point import TestPointAgent
from app.agents.planner import Planner
from app.workflow.merge import merge_generation_context


LLM_TIMEOUT_SECONDS = 1800  # â­ 5 åˆ†é’Ÿ


class Orchestrator:
    """
    Orchestratorï¼ˆå·¥ç¨‹çº§ Â· æ°¸ä¸æ²‰é»˜ç‰ˆï¼‰

    ä¿éšœåŽŸåˆ™ï¼š
    1ï¸âƒ£ run_streaming å¿…é¡» yield
    2ï¸âƒ£ LLM å‡ºé—®é¢˜ â‰  SSE å¡æ­»
    3ï¸âƒ£ æœ€å·®æƒ…å†µä¹Ÿè¦è¿”å›žå…œåº•ç”¨ä¾‹
    """

    def __init__(self):
        pass

    # =====================================================
    # ðŸš€ éœ€æ±‚åˆ†æž + æµ‹è¯•ç‚¹ç”Ÿæˆ
    # =====================================================
    def run(
        self,
        raw_requirements: str,
        confirmed_items: List[str] | None = None,
        mode: str = "DELIVERY",
        focus_requirements: str | None = None,  # â­ æ–°å¢ž
    ) -> Dict[str, Any]:

        confirmed_items = confirmed_items or []

        # =================================================
        # 1ï¸âƒ£ éœ€æ±‚åˆ†æžï¼ˆå¼ºåŒ– focusï¼‰
        # =================================================
        analysis_prompt = f"""
ä½ æ˜¯ä¸€åèµ„æ·±è½¯ä»¶æµ‹è¯•ä¸“å®¶ã€‚

è¯·å¯¹ä»¥ä¸‹éœ€æ±‚è¿›è¡Œã€éœ€æ±‚åˆ†æžã€‘ï¼š
- æ€»ä½“è´¨é‡è¯„ä¼°
- æ½œåœ¨é£Žé™©
- æµ‹è¯•å»ºè®®
âš ï¸ ä¸è¦ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹

ã€éœ€æ±‚å†…å®¹ã€‘
{raw_requirements}

ã€ç”¨æˆ·è¡¥å……æµ‹è¯•é‡ç‚¹ï¼ˆå¿…é¡»é‡ç‚¹è€ƒè™‘ï¼‰ã€‘
{focus_requirements or "æ— "}

è¯·è¿”å›ž JSONï¼š
{{
  "summary": {{
    "quality": 0,
    "comment": ""
  }},
  "issues": [],
  "risks": [],
  "suggestions": []
}}
"""

        analysis = llm.call(analysis_prompt)

        if not isinstance(analysis, dict):
            raise RuntimeError("éœ€æ±‚åˆ†æžé˜¶æ®µï¼šLLM è¿”å›žéž JSON")

        summary = analysis.get("summary") or {
            "quality": 70,
            "comment": "AI å·²å®Œæˆéœ€æ±‚åˆ†æž",
        }

        # =================================================
        # 2ï¸âƒ£ Plannerï¼šç”Ÿæˆè®¡åˆ’ï¼ˆðŸ”¥å…³é”®ï¼‰
        # =================================================
        plans = Planner.make_plan(
            requirement=raw_requirements,
            focus_requirements=focus_requirements,
        )

        # =================================================
        # 3ï¸âƒ£ æ ¹æ®è®¡åˆ’ç”Ÿæˆæµ‹è¯•ç‚¹
        # =================================================
        test_point_agent = TestPointAgent()
        test_points: List[Dict[str, Any]] = []

        for plan in plans:
            plan_type = plan.get("type", "normal")

            tp_output = test_point_agent.run({
                "instruction": plan.get("instruction"),
                "type": plan_type,
                "module": plan.get("module"),
                "coverage_item": plan.get("coverage_item"),
            })

            if isinstance(tp_output, dict):
                test_points.extend(
                    tp_output.get("test_points")
                    or tp_output.get("points")
                    or []
                )
            elif isinstance(tp_output, list):
                test_points.extend(tp_output)

        if not test_points:
            raise RuntimeError("AI æœªç”Ÿæˆä»»ä½•æµ‹è¯•ç‚¹ï¼ˆtest_points ä¸ºç©ºï¼‰")

        return {
            "summary": summary,
            "modules": [],
            "test_points": test_points,
            "requirements": [
                tp.get("name")
                for tp in test_points
                if isinstance(tp, dict) and tp.get("name")
            ],
            "issues": analysis.get("issues") or [],
            "risks": analysis.get("risks") or [],
            "suggestions": analysis.get("suggestions") or [],
        }

    # =====================================================
    # âœ… æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆï¼ˆStreamingï¼‰
    # =====================================================
    def run_streaming(
        self,
        raw_requirements: str,
        test_points: List[Dict[str, Any]],
        confirmed_items: List[str] | None = None,
        requirement_hint: str | None = None,
        analysis_result: Dict[str, Any] | None = None,
        focus_requirements: str | None = None,  # â­ æ–°å¢ž
    ) -> Generator[Dict[str, Any], None, None]:

        confirmed_items = confirmed_items or []

        if not test_points:
            raise RuntimeError("æ— æµ‹è¯•ç‚¹ï¼Œç¦æ­¢ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")

        merged = merge_generation_context(
            raw_requirements=raw_requirements,
            user_requirement=requirement_hint,
            analysis_result=analysis_result,
        )
        merged_requirements = merged["merged_requirements"]

        idx = 0
        yielded_any = False

        try:
            for raw_case in self._stage_cases_stream(
                merged_requirements,
                test_points,
                confirmed_items,
                focus_requirements,  # â­ ä¼ ä¸‹åŽ»
            ):
                idx += 1
                yielded_any = True
                normalized = self._normalize_case(raw_case)
                normalized["_index"] = idx
                yield normalized

        except Exception as e:
            print("âŒ run_streaming error:", e)
            traceback.print_exc()

        # =================================================
        # ðŸ›Ÿ å…œåº•
        # =================================================
        if not yielded_any:
            yield {
                "_index": 1,
                "case_name": "ã€ç³»ç»Ÿå…œåº•ã€‘æœªèƒ½ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹",
                "module": "SYSTEM",
                "precondition": "",
                "steps": [
                    "AI åœ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ—¶å‘ç”Ÿå¼‚å¸¸æˆ–è¶…æ—¶",
                    "è¯·æ£€æŸ¥ LLM æœåŠ¡çŠ¶æ€ / prompt è¾“å‡º",
                ],
                "expected": "ç³»ç»Ÿåº”æç¤ºç”Ÿæˆå¤±è´¥åŽŸå› ",
                "test_point_id": None,
                "test_point_name": None,
            }

    # =====================================================
    # â­ LLM ç”¨ä¾‹ç”Ÿæˆï¼ˆçœŸæ­£å¯æŽ§è¶…æ—¶ Â· 5 åˆ†é’Ÿï¼‰
    # =====================================================
    def _stage_cases_stream(
        self,
        raw_requirements: str,
        test_points: List[Dict[str, Any]],
        confirmed_items: List[str],
        focus_requirements: str | None = None,  # â­ æ–°å¢ž
    ) -> Generator[Dict[str, Any], None, None]:

        # ðŸ”¥ å…³é”®ä¿®æ”¹ï¼šå¼ºåˆ¶ precondition
        prompt = f"""
ä½ æ˜¯ä¸€åèµ„æ·±è½¯ä»¶æµ‹è¯•ä¸“å®¶ã€‚

è¯·åŸºäºŽä»¥ä¸‹ã€æµ‹è¯•ç‚¹ã€‘ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼š

ã€ç”Ÿæˆè§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ã€‘
1. æ¯ä¸ªæµ‹è¯•ç‚¹ â‰¥ 3 æ¡ï¼ˆæ­£å¸¸ / å¼‚å¸¸ / è¾¹ç•Œï¼‰
2. è¿”å›ž JSON æ•°ç»„
3. æ¯æ¡ç”¨ä¾‹ã€å¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µã€‘ï¼š
   - case_name
   - module
   - precondition
   - stepsï¼ˆæ•°ç»„ï¼‰
   - expected

ã€å…³äºŽ precondition çš„å¼ºåˆ¶è¯´æ˜Žã€‘
- precondition è¡¨ç¤ºã€æ‰§è¡Œè¯¥ç”¨ä¾‹å‰å¿…é¡»æ»¡è¶³çš„çŠ¶æ€ã€‘
- åªèƒ½æè¿°â€œçŠ¶æ€ / å‰æâ€ï¼Œä¸èƒ½å†™æ“ä½œæ­¥éª¤
- ä¸å…è®¸ä¸ºç©º
- å¦‚æžœæ— ç‰¹æ®Šå‰ç½®æ¡ä»¶ï¼Œè¯·å†™ï¼šâ€œæ— ç‰¹æ®Šå‰ç½®æ¡ä»¶â€

ã€ç”¨æˆ·è¡¥å……æµ‹è¯•é‡ç‚¹ï¼ˆå¿…é¡»é‡ç‚¹è¦†ç›–ï¼‰ã€‘
{focus_requirements or "æ— "}

ã€éœ€æ±‚å†…å®¹ã€‘
{raw_requirements}

ã€æµ‹è¯•ç‚¹ã€‘
{json.dumps(test_points, ensure_ascii=False, indent=2)}
"""

        raw = None

        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(llm.call, prompt)
            try:
                raw = future.result(timeout=LLM_TIMEOUT_SECONDS)
            except TimeoutError:
                print(f"âŒ llm.call timeout (>{LLM_TIMEOUT_SECONDS}s)")
                return
            except Exception as e:
                print("âŒ llm.call exception:", e)
                return

        if isinstance(raw, str):
            raw = re.sub(r"^```json|```$", "", raw.strip(), flags=re.I)
            try:
                raw = json.loads(raw)
            except Exception as e:
                print("âŒ JSON parse failed:", e)
                return

        cases = self._safe_parse_cases(raw)

        for case in cases:
            yield case

    # =====================================================
    # ç”¨ä¾‹è§„èŒƒåŒ–
    # =====================================================
    def _normalize_case(self, raw: Dict[str, Any]) -> Dict[str, Any]:
        steps = raw.get("steps") or []
        if isinstance(steps, str):
            steps = [steps]

        return {
            "case_name": raw.get("case_name") or "æœªå‘½åç”¨ä¾‹",
            "module": raw.get("module", ""),
            "precondition": raw.get("precondition", ""),
            "steps": steps,
            "expected": raw.get("expected", ""),
            "test_point_id": raw.get("test_point_id"),
            "test_point_name": raw.get("test_point_name"),
        }

    def _safe_parse_cases(self, raw: Any) -> List[Dict[str, Any]]:
        if isinstance(raw, list):
            return [c for c in raw if isinstance(c, dict)]

        if isinstance(raw, dict):
            cases = raw.get("cases")
            if isinstance(cases, list):
                return [c for c in cases if isinstance(c, dict)]

        return []
